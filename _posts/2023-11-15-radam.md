---
layout: post
title: "RADAM paper published!"
date: 2023-11-15
excerpt: "Our novel and state-of-the-art texture recognition technique."
image: assets/images/post_imgs/radam.png
---


Texture analysis is a classical yet challenging task in computer vision for which deep neural networks are actively being applied. Most approaches are based on building feature aggregation modules around a pre-trained backbone and then fine-tuning the new architecture on specific texture recognition tasks. Here we propose a new method named Random encoding of Aggregated Deep Activation Maps (RADAM) which extracts rich texture representations without ever changing the backbone. The technique consists of encoding the output at different depths of a pre-trained deep convolutional network using a Randomized Autoencoder (RAE). The RAE is trained locally to each image using a closed-form solution, and its decoder weights are used to compose a 1-dimensional texture representation that is fed into a linear SVM. This means that no fine-tuning or backpropagation is needed for the backbone. We explore RADAM on several texture benchmarks and achieve state-of-the-art results with different computational budgets. Our results suggest that pre-trained backbones may not require additional fine-tuning for texture recognition if their learned representations are better encoded.



<a href="https://paperswithcode.com/sota/image-classification-on-dtd" target="_blank" rel="noopener noreferrer"><i class="fa-solid fa-medal"></i> State-of-the-art on DTD!</a>

<a href="https://doi.org/10.1016/j.patcog.2023.109802" target="_blank" rel="noopener noreferrer"><i class="fa-solid fa-scroll"></i> Full paper at the Pattern Recognition journal.</a>

<a href="https://arxiv.org/abs/2303.04554" target="_blank" rel="noopener noreferrer"><i class="fa-solid fa-scroll"></i> arXiv preprint.</a>

<a href="https://github.com/scabini/RADAM" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i> The model is open source!</a>



